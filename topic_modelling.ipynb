{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "# import multiprocessing\n",
    "import operator\n",
    "import string\n",
    "\n",
    "import joblib\n",
    "import textblob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "# from sklearn.decomposition import NMF\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_csv('quora_challenge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['question_text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['question_len'] = X['question_text'].str.len()\n",
    "\n",
    "# fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "# fig.suptitle('Question Length Distribution', fontsize=16)\n",
    "\n",
    "# sns.violinplot(X['question_len'], inner='quartile', orient='h', ax=ax0)\n",
    "# ax0.set_xlabel('Character Length')\n",
    "\n",
    "# sns.violinplot(X['question_len'], inner='quartile', orient='h', ax=ax1)\n",
    "# ax1.set_xscale('log')\n",
    "# ax1.set_xlabel('Character Length (Log Scale)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = 'cache'\n",
    "memory = joblib.Memory(cachedir, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def asciitize(text):\n",
    "    print('ascii')\n",
    "    return ''.join(char for char in text if char in string.printable)\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def depunctuate(text):\n",
    "    print('punc')\n",
    "    return ''.join(char if char not in string.punctuation else ' ' for char in text)\n",
    "\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *, target_col='question_text', result_col='cleaned_text', \n",
    "                 pos='anvr', stop_words=None, n_jobs=None):\n",
    "        self.target_col = str(target_col)\n",
    "        self.result_col = str(result_col)\n",
    "        self.pos = tuple(pos.lower()) if isinstance(pos, str) else tuple(pos)\n",
    "        self.stop_words = () if stop_words is None else frozenset(stop_words)\n",
    "        self.n_jobs = n_jobs if n_jobs is None else int(n_jobs)\n",
    "        self.lemmatize = memory.cache(self.lemmatize)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.result_col] = (X[self.target_col].str.lower()\n",
    "                                                .map(asciitize)\n",
    "                                                .map(depunctuate)\n",
    "                                                .map(self.lemmatize))\n",
    "        return X[self.result_col].values\n",
    "    \n",
    "    def lemmatize(self, text):\n",
    "        print('lemma')\n",
    "        tag_dict = dict(J='a', N='n', V='v', R='r')\n",
    "        blob = textblob.TextBlob(text)\n",
    "        \n",
    "        try:\n",
    "            words, tags = zip(*blob.pos_tags)\n",
    "        except ValueError:\n",
    "            return ''\n",
    "        \n",
    "        tags = (tag_dict.get(tag[0]) for tag in tags)\n",
    "        lemmas = (word.lemmatize(tag) for word, tag in zip(words, tags)\n",
    "                  if tag in self.pos\n",
    "                  if word not in self.stop_words)\n",
    "        result = ' '.join(lem for lem in lemmas if lem not in self.stop_words)\n",
    "        return result if result else ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicLabeller(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        topics = np.argmax(X, axis=1)\n",
    "        weights = np.max(X, axis=1)\n",
    "        return np.vstack([topics, weights]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF as _NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as _TfidfVectorizer\n",
    "\n",
    "class DebugMixin:\n",
    "    def fit(self, X, y=None):\n",
    "        print(type(self).__name__, 'fit')\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        print(type(self).__name__, 'fit')\n",
    "        return super().transform(X, y)\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        print(type(self).__name__, 'fit')\n",
    "        return super().fit_transform(X, y)\n",
    "\n",
    "    \n",
    "class NMF(_NMF):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fit = memory.cache(self.fit)\n",
    "        self.transform = memory.cache(self.transform)\n",
    "        self.fit_transform = memory.cache(self.fit_transform)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(type(self).__name__, 'fit')\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        print(type(self).__name__, 'trans')\n",
    "        return super().transform(X, y)\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        print(X.toarray()[:2, :10\n",
    "                         ])\n",
    "        print(type(self).__name__, 'ft')\n",
    "        return super().fit_transform(X, y)\n",
    "        \n",
    "class TfidfVectorizer(_TfidfVectorizer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fit = memory.cache(self.fit)\n",
    "        self.transform = memory.cache(self.transform)\n",
    "        self.fit_transform = memory.cache(self.fit_transform)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        print(type(self).__name__, 'fit')\n",
    "        return super().fit(X, y)\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        print(type(self).__name__, 'trans')\n",
    "        return super().transform(X, y)\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        print(type(self).__name__, 'ft')\n",
    "        return super().fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_STOP_WORDS = frozenset(\"does doesn doesnt don dont im ive make quora really shouldnt youll ve weve wouldnt\".split())\n",
    "NOT_STOP_WORDS = frozenset(\"cry system\".split())\n",
    "CUSTOM_STOP_WORDS = ENGLISH_STOP_WORDS | EXTRA_STOP_WORDS - NOT_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_kwds = dict(\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=None,\n",
    "    lowercase=False,\n",
    "    max_df=0.9,\n",
    "    max_features=25_000,\n",
    ")\n",
    "\n",
    "decomp_kwds = dict(\n",
    "#     n_components=50,\n",
    "    n_components=2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "topic_model_pipe = Pipeline([\n",
    "    ('textprep', TextPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer(**vector_kwds)),\n",
    "    ('decomposer', NMF(**decomp_kwds)),\n",
    "    ('labeller', TopicLabeller()),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5314277071055553998, -9223372036546027818)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_hash = hash(str(topic_model_pipe))\n",
    "pipe_hash, hash(topic_model_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "pipe_hash = hash(str(topic_model_pipe))\n",
    "pipe_file = f'pipe_{pipe_hash}.joblib'\n",
    "try:\n",
    "    topic_model_pipe = joblib.load(pipe_file)\n",
    "    print('loaded')\n",
    "except FileNotFoundError:\n",
    "    joblib.dump(topic_model_pipe, pipe_file)\n",
    "    print('dumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('textprep',\n",
       "                 TextPreprocessor(n_jobs=None, pos=('a', 'n', 'v', 'r'),\n",
       "                                  result_col='cleaned_text', stop_words=(),\n",
       "                                  target_col='question_text')),\n",
       "                ('vectorizer', TfidfVectorizer()), ('decomposer', NMF()),\n",
       "                ('labeller', TopicLabeller())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5314277071055553998, 308747966)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_hash, hash(topic_model_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308981803"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = _TfidfVectorizer()\n",
    "hash(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308747966"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(topic_model_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308747966"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(topic_model_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>do quebec nationalist see province nation 1960s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>do have adopt dog encourage people adopt not shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>do velocity affect time do velocity affect spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>do otto von guericke use magdeburg hemisphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>i convert montra helicon d mountain bike just ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog, how would you enco...   \n",
       "2  Why does velocity affect time? Does velocity a...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0    do quebec nationalist see province nation 1960s  \n",
       "1  do have adopt dog encourage people adopt not shop  \n",
       "2  do velocity affect time do velocity affect spa...  \n",
       "3      do otto von guericke use magdeburg hemisphere  \n",
       "4  i convert montra helicon d mountain bike just ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .......... (step 1 of 4) Processing textprep, total=   0.0s\n",
      "TfidfVectorizer ft\n",
      "[Pipeline] ........ (step 2 of 4) Processing vectorizer, total=   0.0s\n",
      "[[0.28493151 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.46730248 0.23365124 0.23365124 0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "NMF ft\n",
      "[Pipeline] ........ (step 3 of 4) Processing decomposer, total=   0.0s\n",
      "[Pipeline] .......... (step 4 of 4) Processing labeller, total=   0.0s\n",
      "textpreprocessor_tfidfvectorizer_nmf_topiclabeller_topics2_mxfeat25000\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('quora_challenge.csv', nrows=5)\n",
    "\n",
    "# topic_model_pipe = Pipeline([\n",
    "#     ('textprep', TextPreprocessor()),\n",
    "#     ('vectorizer', TfidfVectorizer(**vector_kwds)),\n",
    "#     ('decomposer', NMF(**decomp_kwds)),\n",
    "#     ('labeller', TopicLabeller()),\n",
    "# ], verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_new = topic_model_pipe.fit_transform(X)\n",
    "\n",
    "file_prefix = ('_'.join(type(step).__name__ for step in topic_model_pipe.named_steps.values()).lower()\n",
    "               + f'_topics{topic_model_pipe[\"decomposer\"].n_components}'\n",
    "               + f'_mxfeat{topic_model_pipe[\"vectorizer\"].max_features}'\n",
    "              )\n",
    "print(file_prefix)\n",
    "\n",
    "# joblib.dump(topic_model_pipe, f'{file_prefix}__pipeline.joblib')\n",
    "# joblib.dump(X_new, f'{file_prefix}__X_new.joblib');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['topic'] = X_new[:, 0]\n",
    "X['weight'] = X_new[:, 1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['topic'] = X_new[:, 0]\n",
    "X['weight'] = X_new[:, 1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_words(pipeline, n_top=8):\n",
    "    feature_names = pipeline['vectorizer'].get_feature_names()\n",
    "    pyfunc = functools.partial(operator.getitem, feature_names)\n",
    "    vfunc = np.vectorize(pyfunc)\n",
    "\n",
    "    components = pipeline['decomposer'].components_\n",
    "    word_idxs = components.argsort(axis=1)[:, -n_top:][:, ::-1]\n",
    "    words = vfunc(word_idxs)\n",
    "\n",
    "    top_words_df = pd.DataFrame(words.T, columns=[f'Topic {i}' for i in range(len(words))])\n",
    "    top_words_df.index.name = 'Top Words'\n",
    "    \n",
    "    return top_words_df\n",
    "\n",
    "top_words_df = extract_top_words(topic_model_pipe)\n",
    "top_words_df\n",
    "\n",
    "# joblib.dump(top_words_df, f'{file_prefix}__top_words.joblib')\n",
    "# top_words_df.to_csv(f'file_prefix}__top_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic count distribution\n",
    "topics = X['topic']\n",
    "x, y = np.vstack(np.unique(topics, return_counts=True))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(x, y, palette='GnBu_d')\n",
    "plt.title('Topic Distribution')\n",
    "plt.xticks(ticks=range(len(x)))\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# plt.savefig(f'{file_prefix}__topic_dist.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = np.ceil(X['weight'].max() * 100) / 100\n",
    "xs = np.linspace(0, stop, 1000)\n",
    "ys = np.empty_like(xs)\n",
    "for i, x in enumerate(xs):\n",
    "    ys[i] = np.sum(X['weight'] > x) / len(X)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "fig.suptitle('Ratio of Question Weights Above Threshold', fontsize=16)\n",
    "\n",
    "ax0.plot(xs, ys)\n",
    "ax0.set_xlabel('Weight Threshold')\n",
    "ax0.set_ylabel('Ratio')\n",
    "\n",
    "ax1.plot(xs, ys)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Weight Threshold (Log Scale)')\n",
    "ax1.set_ylabel('Ratio')\n",
    "\n",
    "# plt.savefig(f'{file_prefix}__thresh_ratio.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_sentences(n_sents=3):\n",
    "    for group, df in X.groupby('topic'):\n",
    "        print('Topic', group)\n",
    "\n",
    "        repr_idxs = df['weight'].argsort()[-n_sents:].values\n",
    "        repr_wghts = df['weight'].sort_values()[-n_sents:].values.round(4)    \n",
    "        repr_sents = df['question_text'].values[repr_idxs]\n",
    "\n",
    "        for sent, wght in zip(repr_sents, repr_wghts):\n",
    "            print('\\t', wght, sent)\n",
    "\n",
    "        print('-' * 100)\n",
    "        \n",
    "representative_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sentences(n_sents=3, random_state=None):\n",
    "    for group, df in X.groupby('topic'):\n",
    "        print('Topic', group)\n",
    "        \n",
    "        sample = df.sample(n_sents, random_state=random_state)\n",
    "        rand_sents = sample['question_text'].values\n",
    "        rand_wghts = sample['weight'].values.round(4)\n",
    "        \n",
    "        for sent, wght in zip(rand_sents, rand_wghts):\n",
    "            print('\\t', wght, sent)\n",
    "\n",
    "        print('-' * 100)\n",
    "        \n",
    "random_sentences(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
